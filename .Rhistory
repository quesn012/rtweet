posterior <- posterior(results)[[2]]
# look at the posterior topic distribution for the dth document and plot it visually
d = '1_yellowpages.txt'
n = 1
posterior[1,]
barplot(posterior[n,])
# Examine the main topic for document document 1
Terms[[which.max(posterior[1,])]]
# Compare the keyword of document 1 to the terms. keywords$query[d]
keywords <- key
keywords$query <- as.character(keywords$query)
keywords$query[n]
# look at the posterior topic distribution for the dth document and plot it visually
d = 2
n = 10
posterior[d,]
barplot(posterior[d,])
# Examine the main topic for document document 1
Terms[[which.max(posterior[d,])]]
# Compare the keyword of document 1 to the terms. keywords$query[d]
keywords$query[n]
# look at the posterior topic distribution for the dth document and plot it visually
d = 3
n = 100
posterior[d,]
barplot(posterior[d,])
# Examine the main topic for document document 1
Terms[[which.max(posterior[d,])]]
# Compare the keyword of document 1 to the terms. keywords$query[d]
keywords$query[n]
# look at the posterior topic distribution for the dth document and plot it visually
d = 4
n = 1000
posterior[d,]
barplot(posterior[d,])
# Examine the main topic for document document 1
Terms[[which.max(posterior[d,])]]
# Compare the keyword of document 1 to the terms. keywords$query[d]
keywords$query[n]
entropy_single <- function(probs)
{
b_probs <- 1-probs
-sum((probs * log2(probs) + b_probs * log2(b_probs)))
}
entropy <- function(probs_vector)
{
j <- 0
for (i in 1:length(probs_vector))
j <-  j + (probs_vector[i] * log2(probs_vector[i]))
-j
}
a <- seq(.01,.99,.01)
b <- a
c <- data.frame(b,a)
c[2] <- apply(c[2],1, entropy_single)
ggplot(c,aes(b,a)) + geom_line()
#create data frame
poster_df <- data.frame(posterior)
poster_df$names <- row.names(poster_df)
#extract numbers, then add back in to poster_df
post_order <- as.numeric(gsub("([0-9]+).*$", "\\1", poster_df$names))
poster_df$post_order <- post_order
#calculating entropy and adding it in to poster_DF
poster_df$entropy <- apply(posterior, 1, entropy)
#sorty by post_order
poster_df <- poster_df[order(post_order),]
#add in to keys
key$entropy <- as.numeric(poster_df$entropy)
entrop_key <- within(key, remove(querycode,query,num_clicks,num_impressions, categoryid, log_imp))
#entrop_key$categoryid <- as.factor(reg_key_category$categoryid)
entrop_fit <- train(ctr ~ ., data = entrop_key,
method = 'glm')
entrop_fit
summary(entrop_fit)
poster_df[824,]
key[824,]
#target = document 824
Terms[[which.max(posterior["824_target.txt",])]]
barplot(posterior["824_target.txt",])
# Examine the main topic for document document 1
ggplot(key,aes(ctr)) + geom_density() + geom_point(aes(.03799,.94)) #this is roughly target's location on the curve
ggplot(key,aes(avg_ad_quality)) + geom_density() + geom_point(aes(.00827,8.9)) #this is roughly target's location on the curve
ggplot(key,aes(entropy)) + geom_density()
#are key words too amibgious? this is the question
#look at entropy.
key[824 , ]$entropy
mean(key$entropy)
#walmart entropy
key[6 , ]$entropy
cat8_cat <- key[key$categoryid == 8, 2]
cat8_ctr <- key[key$categoryid == 8, 14]
cat8 <- data.frame(cat8_cat,cat8_ctr)
cat8 <- cat8[order(cat8_ctr),]
cat8[1:5,]
cat_ctr <- key %>%
group_by(categoryid) %>%
summarise(
avg_ctr = mean(ctr)
)
ggplot(cat_ctr,aes(categoryid,avg_ctr)) + geom_col()
cat13_query <- key[key$categoryid == 13 , ]$query
cat13_ctr <- key[key$categoryid == 13 , ]$ctr
cat13_impressions <- key[key$categoryid == 13 , ]$num_impressions
cat13 <- data.frame(cat13_query,cat13_ctr,cat13_impressions)
cat13 <- cat13[order(-cat13_ctr) , ]
cat13[1:18,]
View(key)
cat[824, ]
key[824 , ]
comp1 <- data.frame(key[824 , ],key[23 , ],key[22 , ],key[32 , ])
comp1
ggplot(comp1,aes(query,num_impressions))
ggplot(comp1,aes(query,num_impressions)) + geom_col()
comp1
comp1 <- data.frame(rbind(key[824 , ],key[23 , ],key[22 , ],key[32 , ]))
comps1
comp1
ggplot(comp1,aes(query,num_impressions)) + geom_col()
key1 <- read.csv('keywords.csv')
key_nonnorm <- key1
key[23,]
comp1 <- data.frame(rbind(key[824 , ],key[411 , ],key[655 , ],key[966 , ]))
ggplot(comp1,aes(query,num_impressions)) + geom_col()
ggplot(comp1,aes(query,ctr)) + geom_col()
ggplot(comp1,aes(query,entropy)) + geom_col()
comp1 <- data.frame(rbind(key[824 , ],key[411 , ],key[998 , ],key[966 , ]))
ggplot(comp1,aes(query,num_impressions)) + geom_col()
ggplot(comp1,aes(query,ctr)) + geom_col()
ggplot(comp1,aes(query,entropy)) + geom_col()
ggplot(comp1,aes(query,entropy)) + geom_col()
ggplot(comp1,aes(query,num_impressions)) + geom_col()
ggplot(comp1,aes(query,ctr)) + geom_col()
options(repos = c(CRAN = "https://cran.microsoft.com/snapshot/2016-11-02"))
getOption("repos")
install.packages(c("dplyr","ggplot2","httr","devtools","tidyverse",
"knitr","tidyr","readr","lubridate","readxl","broom",
"memoise","assertthat","microbenchmark",
"pander","purrr","caret","stringr",
"TSA","fpp","forecast","zoo","xts",
"lpSolve",
"sparklyr","versions","checkpoint",
"igraph",
"LearnBayes","MCMCpack",
"VGAM","quantreg","mvtnorm","sandwich"),
dep=TRUE,
repos="https://cran.microsoft.com/snapshot/2016-11-02")
q2 <- memoise(function(P) {
if (!is.integer(P)) stop ("P must contain integers")
N <- length(P) # the total number of supercharger locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Your solution should work for any vector P of any length
# Write your code here
#base case
if (N <= 0L) return(0L)
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
q2(P[3:N]) + P[1],
q2(P[2:N])
)
})
q2(P = c(2L,6L,5L)) #7
q2(P = c(1L,5L)) #5
q2(P = c(6L,2L,3L,5L)) #11 - 6 + 5
q2(P = c(7L,9L,4L,5L,12L,8L)) #should be 23 (12 + 4 + 7)
# set global chunk options
library(knitr)
opts_chunk$set(echo=TRUE)
suppressPackageStartupMessages({
library(TSA)
library(jsonlite) # in order to use fromJSON
library(memoise)
library(assertthat)
library(xts)
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
})
set.seed(123456)
q2 <- memoise(function(P) {
if (!is.integer(P)) stop ("P must contain integers")
N <- length(P) # the total number of supercharger locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Your solution should work for any vector P of any length
# Write your code here
#base case
if (N <= 0L) return(0L)
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
q2(P[3:N]) + P[1],
q2(P[2:N])
)
})
q2(P = c(2L,6L,5L)) #7
q2(P = c(1L,5L)) #5
q2(P = c(6L,2L,3L,5L)) #11 - 6 + 5
q2(P = c(7L,9L,4L,5L,12L,8L)) #should be 23 (12 + 4 + 7)
q2(P = c(10L,1L,1L,13L,12L))
q2(P = c(10L,1L,13L,12L))
q2(P = c(10L,1L,13L,12L,2L))
q2(P = c(10L,1L,13L,12L,2L,17L,18L))
18+13+2+10
q2(P = c(10L,1L,13L,12L,2L,17L,18L,10L))
10 + 17 + 13 + 10
q2(P = c(10L,1L,13L,12L,2L,17L,18L,10L,7L,6L,6L))
q2(P = c(10L,1L,13L,12L,2L,17L,18L,10L,7L,30L,6L))
1 + 12 + 17 + 10 + 30 + 6
30 + 10 + 17 + 12 + 10
30 + 18 + 13  + 10
13 + 10 + 17 + 10 + 30
q3 <- memoise(function(B, C, P) {
if (!is.integer(B) || !is.integer(C) || !is.integer(P))
stop ("B, C and P must contain integers")
if (length(C) != length(P))
stop ("Both P and C must be the same length")
#N <- length(P) # the total number of gas station locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Write your code here
D <- C <= B
C <- C[D]
P <- P[D]
N <- length(P)
if (B < min(C) | N <= 0L | B <= 0L) return(0L)  #problem is NA's are in the list of P here
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
( ifelse(B - C[1]>=0, (q3(B - C[1], C[3:N], P[3:N]) + P[1]), 0)),
( q3(B, C[2:N], P[2:N]))
)
})
# Please print the result of that line below
q3(B = 11L, C = c(2L, 1L, 4L, 3L, 1L),P = c(9L, 4L, 17L, 8L, 3L))
#b = 4L
#c = c(2L, 1L, 4L, 3L, 1L)
#p = c(9L, 4L, 17L, 8L, 3L)
q3 <- memoise(function(B, C, P) {
if (!is.integer(B) || !is.integer(C) || !is.integer(P))
stop ("B, C and P must contain integers")
if (length(C) != length(P))
stop ("Both P and C must be the same length")
#N <- length(P) # the total number of gas station locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Write your code here
D <- C <= B
C <- C[D]
P <- P[D]
N <- length(P)
if (B < min(C) | N <= 0L | B <= 0L) return(0L)  #problem is NA's are in the list of P here
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
( ifelse(B - C[1]>=0, (q3(B - C[1], C[3:N], P[3:N]) + P[1]), 0)),
( q3(B, C[2:N], P[2:N]))
)
})
# Please print the result of that line below
q3(B = 11L, C = c(2L, 1L, 4L, 3L, 1L),P = c(9L, 4L, 1L, 8L, 3L))
#b = 4L
#c = c(2L, 1L, 4L, 3L, 1L)
#p = c(9L, 4L, 17L, 8L, 3L)
9 + 4 + 8 + 3
q3 <- memoise(function(B, C, P) {
if (!is.integer(B) || !is.integer(C) || !is.integer(P))
stop ("B, C and P must contain integers")
if (length(C) != length(P))
stop ("Both P and C must be the same length")
#N <- length(P) # the total number of gas station locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Write your code here
D <- C <= B
C <- C[D]
P <- P[D]
N <- length(P)
if (B < min(C) | N <= 0L | B <= 0L) return(0L)  #problem is NA's are in the list of P here
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
( ifelse(B - C[1]>=0, (q3(B - C[1], C[3:N], P[3:N]) + P[1]), 0)),
( q3(B, C[2:N], P[2:N]))
)
})
# Please print the result of that line below
q3(B = 11L, C = c(2L, 1L, 4L, 3L, 1L),P = c(9L, 4L, 17L, 8L, 3L))
#b = 4L
#c = c(2L, 1L, 4L, 3L, 1L)
#p = c(9L, 4L, 17L, 8L, 3L)
# Chunk 1
# set global chunk options
library(knitr)
opts_chunk$set(echo=TRUE)
suppressPackageStartupMessages({
library(TSA)
library(jsonlite) # in order to use fromJSON
library(memoise)
library(assertthat)
library(xts)
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
})
set.seed(123456)
# Chunk 2
btc_data <- fromJSON("btc.json") # please do not change this line!
btc_price <- flatten(data.frame(btc_data$bpi)) %>% t()
btc_dates <- row.names(btc_price)
btc_dates <- substring(btc_dates, 2)
btc_df <- data.frame(bpi = btc_price, date = btc_dates)
btc_df$date <- gsub("[.]", "/", btc_df$date)
btc_df$date <- ymd(btc_df$date)
btc_ts <- ts(btc_df$bpi)
# Chunk 3
#plot general timeline first
autoplot(btc_ts)
# Chunk 4
#Let's examine it by years.
#making a dataframe so we can look at each year on top of each other
btc_year <- data.frame(year1 = btc_ts[1:365], year2 = btc_ts[366:730], year3 = btc_ts[731:1095], year4 = btc_ts[1096:1460])
#year 1
autoplot(ts(btc_ts[1:365]))
#year 2
autoplot(ts(btc_ts[366:730]))
#year 3
autoplot(ts(btc_ts[731:1095]))
#year 4
autoplot(ts(btc_ts[1096:1462]))
# Chunk 5
#all 4 years together
ggplot(btc_year) + geom_line(aes(1:365,year1, color='year1')) + geom_line(aes(1:365,year2, color='year2')) + geom_line(aes(1:365,year3, color='year3')) + geom_line(aes(1:365,year4, color='year4'))
# Chunk 6
ggplot(btc_year) + geom_line(aes(1:365,year1, color='year1')) + geom_line(aes(1:365,year2, color='year2')) + geom_line(aes(1:365,year3, color='year3'))
# Chunk 7
btc_df$month <- month(btc_df$date)
btc_gb_month <- btc_df %>% group_by(month) %>%
summarise(mean_price = mean(bpi))
ggplot(btc_gb_month) + geom_line(aes(month,mean_price))
# Chunk 8
btc_df$month <- month(btc_df$date)
btc_gb_month2 <- btc_df[1:1096,] %>% group_by(month) %>%
summarise(mean_price = mean(bpi))
ggplot(btc_gb_month2) + geom_line(aes(month,mean_price))
# Chunk 9
#check within month seasonality - take 5 random months and plot them together
btc_month <- data.frame(month1 = btc_ts[1:30], month2 = btc_ts[241:270], month3 = btc_ts[601:630],
month4 = btc_ts[991:1020], month5 = btc_ts[721:750])
#taking months in the first 3 years since the 4th blows up the scale
ggplot(btc_month) + geom_line(aes(1:30,month1, color='month1')) +
geom_line(aes(1:30,month2, color='month2')) +
geom_line(aes(1:30,month3, color='month3')) +
geom_line(aes(1:30,month4, color='month4')) +
geom_line(aes(1:30,month5, color='month5'))
# Chunk 10
#check within month seasonality - take 5 random months and plot them together
btc_week <- data.frame(week1 = btc_ts[1:7], week2 = btc_ts[141:147], week3 = btc_ts[281:287],
week4 = btc_ts[421:427], week5 = btc_ts[561:567],week6 = btc_ts[701:707],
week7 = btc_ts[841:847],week8 = btc_ts[981:987])
#taking months in the first 3 years since the 4th blows up the scale
ggplot(btc_week) + geom_line(aes(1:7,week1, color='week1')) +
geom_line(aes(1:7,week2, color='week2')) +
geom_line(aes(1:7,week3, color='week3')) +
geom_line(aes(1:7,week4, color='week4')) +
geom_line(aes(1:7,week5, color='week5')) +
geom_line(aes(1:7,week6, color='week6')) +
geom_line(aes(1:7,week7, color='week7')) +
geom_line(aes(1:7,week7, color='week8'))
# Chunk 11
btc_df$week <- weekdays.Date(btc_df$date)
btc_gb_week <- btc_df %>% group_by(week) %>%
summarise(mean_price = mean(bpi))
ggplot(btc_gb_week) + geom_bar(stat='identity',aes(week,mean_price))
# Chunk 12
#stationary test
adf.test(btc_ts)
#can see its not stationary. definetly a random walk going on here.
adf.test(diff(btc_ts))
#with lag we do get stationary
# Chunk 13
#acf
ggAcf(btc_ts)
# Chunk 14
ggAcf(diff(btc_ts))
# Chunk 15
#pacf
ggPacf(btc_ts)
# Chunk 16
ggPacf(diff(btc_ts))
# Chunk 17
#eacf
eacf(diff(btc_ts))
# Chunk 18
#try auto arima
auto.arima(btc_ts, stationary = FALSE, seasonal = FALSE)
# Chunk 19
btc_train <- btc_ts[1:1096]
btc_test <- btc_ts[1096:1462]
# Chunk 20
naive_arima_forecast <- naive(btc_train, h=length(btc_test))
accuracy(naive_arima_forecast, btc_test)
# Chunk 21
arima_110 <- Arima(btc_train, order=c(1,1,0))
arima_110_forecast <- forecast(arima_110, h=length(btc_test))
accuracy(arima_110_forecast,btc_test)
# Chunk 22
arima_111 <- Arima(btc_train, order=c(1,1,1))
arima_111_forecast <- forecast(arima_111, h=length(btc_test))
accuracy(arima_110_forecast,btc_test)
# Chunk 23
arima_010 <- Arima(btc_train, order=c(1,1,1))
arima_010_forecast <- forecast(arima_111, h=length(btc_test))
accuracy(arima_010_forecast,btc_test)
# Chunk 24
final_arima <- Arima(btc_ts,order=c(0,1,0))
final_forecast <- forecast(final_arima,h=365)
# Chunk 25
# Produce a ggplot
final_arima_df <- data.frame(mean = final_forecast$mean, upper = final_forecast$upper, lower = final_forecast$lower, date = 1:365)
p1 <- ggplot(final_arima_df) + geom_line(aes(date,mean))
# Don't forget to plot it!
p1
# Please save your forecast for the next 365 days
future_btc <- rep(final_forecast$mean, 365)
# Provide a 95% prediction interval for Bitcoin price in a year from now (365 days)
low <- final_forecast$lower[365]
high <- final_forecast$upper[365]
# Please print them
low
high
# Chunk 26
# Must be a number 1, -1 or 0
answer1 <- 0 # 1 = will go up, -1 = will go down, 0 = can't tell
# Please print it
answer1
# Chunk 27
q2 <- memoise(function(P) {
if (!is.integer(P)) stop ("P must contain integers")
N <- length(P) # the total number of supercharger locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Your solution should work for any vector P of any length
# Write your code here
#base case
if (N <= 0L) return(0L)
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
q2(P[3:N]) + P[1],
q2(P[2:N])
)
})
#q2(P = c(2L,6L,5L)) #7
#q2(P = c(1L,5L)) #5
#q2(P = c(6L,2L,3L,5L)) #11 - 6 + 5
#q2(P = c(7L,9L,4L,5L,12L,8L)) #should be 23 (12 + 4 + 7)
#q2(P = c(10L,1L,13L,12L,2L,17L,18L,10L,7L,30L,6L))
# Chunk 28
# Some manual cases and expected answers
# Basic "sanity" checks
# if only two locations are available you should pick the one with the highest profit
validate_that(q2(P = c(1L,5L)) == 5L)
# greedy solutions don't work:
# say, consider (2,6,5)
# while 6 is the most profitable location it is better to pick 2 + 5
# since they are non-adjacent and can give higher overall profit
# you cannot pick 6 + 5 since they are adjacent
validate_that(q2(P = c(2L,6L,5L)) == 7L)
# If we are facing (6,2,3,5) then
# we can pick 6 + 5 since they are not adjacent to each other
# and give the highest profit
validate_that(q2(P = c(6L,2L,3L,5L)) == 11L)
q3(B = 11L, C = c(2L, 1L, 4L, 3L, 1L),P = c(9L, 4L, 17L, 8L, 3L))
q3 <- memoise(function(B, C, P) {
if (!is.integer(B) || !is.integer(C) || !is.integer(P))
stop ("B, C and P must contain integers")
if (length(C) != length(P))
stop ("Both P and C must be the same length")
#N <- length(P) # the total number of gas station locations
# N should *NOT* be hard coded. The bot will try to feed P which has 10 locations or more.
# Write your code here
D <- C <= B
C <- C[D]
P <- P[D]
N <- length(P)
if (B < min(C) | N <= 0L | B <= 0L) return(0L)  #problem is NA's are in the list of P here
if (N == 1L) return(P[1])
if (N == 2L) return(max(P))
max(
( ifelse(B - C[1]>=0, (q3(B - C[1], C[3:N], P[3:N]) + P[1]), 0)),
( q3(B, C[2:N], P[2:N]))
)
})
# Please print the result of that line below
q3(B = 11L, C = c(2L, 1L, 4L, 3L, 1L),P = c(9L, 4L, 17L, 8L, 3L))
library(knitr)
help(kable)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(caret)
library(Hmisc)
library(knitr)
tweets <- read.csv('tweets.csv',header = TRUE)
users <- read.csv('users.csv', header = TRUE)
setwd("~/GitHub/rtweet")
tweets <- read.csv('tweets.csv',header = TRUE)
users <- read.csv('users.csv', header = TRUE)
kable(head(tweets))
kable(describe(tweets),'html')
kable(describe(tweets))
help(describe)
library(magrittr)
help(describe)
